{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More imports\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")\n",
    "punctuation = set(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "# query text and part from .db\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions;\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # removing some difficult character from the text manually + lower\n",
    "    l = row[0].lower().replace('«','').replace('›','').replace('”', '').replace(\"’\", '').replace(\"“\",'')\n",
    "\n",
    "    # lower party\n",
    "    p = row[1].lower()\n",
    "\n",
    "    # removing urls\n",
    "    ls = re.sub(r'http\\S+', '', l)\n",
    "\n",
    "    # remove punctuation and split\n",
    "    lss = \"\".join([i for i in ls if i not in punctuation]).split()\n",
    "    # remove stop words\n",
    "    lps = [i for i in lss if i not in set(sw)]\n",
    "    # remove any emojis in text\n",
    "    lpss = [i for i in lps if emoji.is_emoji(i) != True]\n",
    "    \n",
    "\n",
    "    # append both to list\n",
    "    convention_data.append([' '.join(lpss), p])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['skip content company careers press freelancers blog × services transcription captions foreign subtitles translation freelancers contact login return transcript library home transcript categories transcripts 2020 election transcripts classic speech transcripts congressional testimony hearing transcripts debate transcripts donald trump transcripts entertainment transcripts financial transcripts interview transcripts political transcripts press conference transcripts speech transcripts sports transcripts technology transcripts aug 21 2020 2020 democratic national convention dnc night 4 transcript rev blog transcripts 2020 election transcripts 2020 democratic national convention dnc night 4 transcript night 4 2020 democratic national convention dnc august 20 read full transcript event transcribe content try rev free save time transcribing captioning subtitling', 'democratic']\n"
     ]
    }
   ],
   "source": [
    "print(convention_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['could taken away doesnt win', 'republican'],\n",
       " ['bernie believes healthcare human right contingent job knows rebuild crumbling infrastructure creating millions goodpaying union jobs combating climate change bernies moral clarity emboldened democratic partys fight justice grassroots energy supporters amended important advances platform bernie continue lead movement helps defeat trump delivers transformational change im excited place nomination name great champion working class senator bernie sanders',\n",
       "  'democratic'],\n",
       " ['thats good thank much appreciate sudha sundari narayanan phenomenal success born india came united states 13 years ago sudha talented software developer husband raising two beautiful wonderful children apples life right',\n",
       "  'republican'],\n",
       " ['weve made history along way', 'democratic'],\n",
       " ['got back', 'republican'],\n",
       " ['small indiana town foundation faith jesus christ laid conviction sprung love people service others church service mike met love life karen married three children michael charlotte audrey',\n",
       "  'republican'],\n",
       " ['big sister protector', 'democratic'],\n",
       " ['mean socialist', 'republican'],\n",
       " ['name judy smith', 'republican'],\n",
       " ['first got elected came washington dc fight issues important community',\n",
       "  'democratic']]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2382 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw):\n",
    "     ret_dict = dict()\n",
    "     \n",
    "     for i in text.split():\n",
    "          if i in fw:\n",
    "               ret_dict[i] = True\n",
    "     \n",
    "          \n",
    "    \n",
    "    \n",
    "     return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'donald': True, 'president': True}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features(\"donald is the president\", feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'people': True, 'american': True, 'america': True}"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_features(\"people are american in america\",feature_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.498\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           republ : democr =     25.8 : 1.0\n",
      "                   votes = True           democr : republ =     23.8 : 1.0\n",
      "             enforcement = True           republ : democr =     21.5 : 1.0\n",
      "                 destroy = True           republ : democr =     19.2 : 1.0\n",
      "                freedoms = True           republ : democr =     18.2 : 1.0\n",
      "                 climate = True           democr : republ =     17.8 : 1.0\n",
      "                supports = True           republ : democr =     17.1 : 1.0\n",
      "                   crime = True           republ : democr =     16.1 : 1.0\n",
      "                   media = True           republ : democr =     14.9 : 1.0\n",
      "                 beliefs = True           republ : democr =     13.0 : 1.0\n",
      "               countries = True           republ : democr =     13.0 : 1.0\n",
      "                 defense = True           republ : democr =     13.0 : 1.0\n",
      "                  defund = True           republ : democr =     13.0 : 1.0\n",
      "                    isis = True           republ : democr =     13.0 : 1.0\n",
      "                 liberal = True           republ : democr =     13.0 : 1.0\n",
      "                religion = True           republ : democr =     13.0 : 1.0\n",
      "                   trade = True           republ : democr =     12.7 : 1.0\n",
      "                    flag = True           republ : democr =     12.1 : 1.0\n",
      "               greatness = True           republ : democr =     12.1 : 1.0\n",
      "                 abraham = True           republ : democr =     11.9 : 1.0\n",
      "                    drug = True           republ : democr =     10.9 : 1.0\n",
      "              department = True           republ : democr =     10.9 : 1.0\n",
      "               destroyed = True           republ : democr =     10.9 : 1.0\n",
      "                   enemy = True           republ : democr =     10.9 : 1.0\n",
      "               amendment = True           republ : democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "Considering Covid and the way that was sensationalized by the Republican party as the \"China Flu\" it is unsurprising that it is one of the strongest indicators of the party. In fact many of the Republican party indicators stem from buzzwords within the populus that are rooted from news sources like Fox News. It is also unsuprising that Democrats most key words are votes and climate as going out and voting was key in the most recent presidential election campaigning and the current climate change issues are at the forefront of the party's, at least, campaign policies. I don't see anything that particularly subverts my expectations for either party. \n",
    "\n",
    "In terms of overall accuracy, the model is at about 50/50 on the test set, and this is likely due to overpredicting republicans as they have more 'informative' words within the model\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "for row in results:\n",
    "    # decode to utf8 then lower then remove some stubborn characters\n",
    "    l = row[2].decode('utf8').lower().replace('”', '').replace(\"’\", '').replace(\"“\",'')\n",
    "    # remove urls\n",
    "    ls = re.sub(r'http\\S+', '', l)\n",
    "    p = row[1].lower()\n",
    "    n = row[0].lower()\n",
    "    # remove punctuation\n",
    "    lp = \"\".join([ch for ch in ls if ch not in punctuation]).split()\n",
    "    # remove stopwords\n",
    "    lps = [i for i in lp if i not in set(sw)]\n",
    "    # remove emojis\n",
    "    lpss = [i for i in lps if emoji.is_emoji(i) != True]\n",
    "    \n",
    "\n",
    "    # create list\n",
    "    tweet_data.append([' '.join(lpss), p])\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast\n",
      "Actual party is democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe rallytogether\n",
      "Actual party is democratic and our classifer says democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans trumpbudget\n",
      "Actual party is democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line\n",
      "Actual party is republican and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: lets make even greater kag\n",
      "Actual party is republican and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im allin216 repbarbaralee scared roadtovictory\n",
      "Actual party is democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serve…\n",
      "Actual party is democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot thats 7000 nonmath majors room help us get\n",
      "Actual party is democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potuss plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail\n",
      "Actual party is democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlas 22 years eastside commitment amp saluted community leaders last nights awards dinner\n",
      "Actual party is democratic and our classifer says republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    converted = conv_features(tweet,feature_words)\n",
    "    estimated_party = classifier.classify(converted)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['republican','democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "    converted = conv_features(tweet,feature_words)\n",
    "    \n",
    "    # get the estimated party\n",
    "    estimated_party = classifier.classify(converted)\n",
    "    prob = classifier.prob_classify(converted)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'republican': defaultdict(int,\n",
       "                         {'republican': 3777, 'democratic': 605}),\n",
       "             'democratic': defaultdict(int,\n",
       "                         {'republican': 4708, 'democratic': 912})})"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Accuracy Score: 46.88%\n",
      "\n",
      "Classifier Precision Score: 86.19%\n",
      "\n",
      "Classifier Recall Score: 16.23%\n"
     ]
    }
   ],
   "source": [
    "print(\"Classifier Accuracy Score:\", str(round((results['republican']['republican'] + results['democratic']['democratic']) / (results['republican']['republican'] + results['democratic']['democratic'] + results['democratic']['republican'] + results['republican']['democratic'])*100, 2))+\"%\")\n",
    "print(\"\")\n",
    "print(\"Classifier Precision Score:\", str(round((results['republican']['republican']) / (results['republican']['republican'] + results['republican']['democratic'])*100, 2)) + \"%\")\n",
    "print(\"\")\n",
    "print(\"Classifier Recall Score:\", str(round((results['democratic']['democratic']) / (results['democratic']['democratic'] + results['democratic']['republican'])*100, 2))+ \"%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "Looking at how the classifier performed on the new data, the results are not great. The model is overtuned for the republican party causing a high precision and low recall to then create a very low overall accuracy. Tweets can be very hard to get a proper read on as sarcasm or quoting the other party does not translate to a model like this. Due to that, there can lead to overpredictions of one class. Additionally, there was not many Democratic feature words up above compared to Republican and this could lead to the overprediction as well. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
